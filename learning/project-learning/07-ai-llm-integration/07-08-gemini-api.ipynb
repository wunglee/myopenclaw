{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07-08: Google Gemini API",
    "",
    "使用 Google Gemini API 进行文本生成和对话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 安装: npm install @google/generative-ai\n",
    "import { GoogleGenerativeAI } from '@google/generative-ai';\n",
    "\n",
    "const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');\n",
    "\n",
    "// ========== 1. 基础文本生成 ==========\n",
    "async function basicGeneration() {\n",
    "  const model = genAI.getGenerativeModel({ model: 'gemini-pro' });\n",
    "\n",
    "  const prompt = 'Write a story about a magic backpack.';\n",
    "  const result = await model.generateContent(prompt);\n",
    "  const response = await result.response;\n",
    "  const text = response.text();\n",
    "\n",
    "  console.log(text);\n",
    "  return text;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ========== 2. 多轮对话 ==========\n",
    "async function chatConversation() {\n",
    "  const model = genAI.getGenerativeModel({ model: 'gemini-pro' });\n",
    "  const chat = model.startChat({\n",
    "    history: [\n",
    "      {\n",
    "        role: 'user',\n",
    "        parts: 'Hello, I have 2 dogs in my house.'\n",
    "      },\n",
    "      {\n",
    "        role: 'model',\n",
    "        parts: 'Great to meet you. What would you like to know?'\n",
    "      }\n",
    "    ],\n",
    "    generationConfig: {\n",
    "      maxOutputTokens: 100\n",
    "    }\n",
    "  });\n",
    "\n",
    "  const msg = 'How many paws are in my house?';\n",
    "  const result = await chat.sendMessage(msg);\n",
    "  const response = await result.response;\n",
    "\n",
    "  console.log(response.text());\n",
    "  // Output: If you have 2 dogs, and each dog has 4 paws, then there are 8 paws in your house.\n",
    "}\n",
    "\n",
    "// 继续对话\n",
    "async function continueChat(chat: any) {\n",
    "  const result = await chat.sendMessage('Tell me more about dogs.');\n",
    "  const response = await result.response;\n",
    "  console.log(response.text());\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ========== 3. 流式响应 ==========\n",
    "async function streamingGeneration() {\n",
    "  const model = genAI.getGenerativeModel({ model: 'gemini-pro' });\n",
    "\n",
    "  const prompt = 'Write a long story about space exploration.';\n",
    "  const result = await model.generateContentStream(prompt);\n",
    "\n",
    "  for await (const chunk of result.stream) {\n",
    "    const chunkText = chunk.text();\n",
    "    process.stdout.write(chunkText);\n",
    "  }\n",
    "}\n",
    "\n",
    "// 流式对话\n",
    "async function streamingChat() {\n",
    "  const model = genAI.getGenerativeModel({ model: 'gemini-pro' });\n",
    "  const chat = model.startChat();\n",
    "\n",
    "  const result = await chat.sendMessageStream(\n",
    "    'Tell me a joke about programming'\n",
    "  );\n",
    "\n",
    "  for await (const chunk of result.stream) {\n",
    "    process.stdout.write(chunk.text());\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ========== 4. 图像理解 (Gemini Pro Vision) ==========\n",
    "import { readFileSync } from 'fs';\n",
    "\n",
    "async function imageUnderstanding() {\n",
    "  const model = genAI.getGenerativeModel({ model: 'gemini-pro-vision' });\n",
    "\n",
    "  const imagePath = './image.png';\n",
    "  const imageData = readFileSync(imagePath);\n",
    "  const base64Image = imageData.toString('base64');\n",
    "\n",
    "  const result = await model.generateContent([\n",
    "    'What is in this image?',\n",
    "    {\n",
    "      inlineData: {\n",
    "        data: base64Image,\n",
    "        mimeType: 'image/png'\n",
    "      }\n",
    "    }\n",
    "  ]);\n",
    "\n",
    "  const response = await result.response;\n",
    "  console.log(response.text());\n",
    "}\n",
    "\n",
    "// 多图像输入\n",
    "async function multiImageInput() {\n",
    "  const model = genAI.getGenerativeModel({ model: 'gemini-pro-vision' });\n",
    "\n",
    "  const image1 = readFileSync('./image1.png').toString('base64');\n",
    "  const image2 = readFileSync('./image2.png').toString('base64');\n",
    "\n",
    "  const result = await model.generateContent([\n",
    "    'Compare these two images:',\n",
    "    {\n",
    "      inlineData: {\n",
    "        data: image1,\n",
    "        mimeType: 'image/png'\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      inlineData: {\n",
    "        data: image2,\n",
    "        mimeType: 'image/png'\n",
    "      }\n",
    "    }\n",
    "  ]);\n",
    "\n",
    "  const response = await result.response;\n",
    "  console.log(response.text());\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ========== 5. 配置参数 ==========\n",
    "async function withConfig() {\n",
    "  const model = genAI.getGenerativeModel({\n",
    "    model: 'gemini-pro',\n",
    "    generationConfig: {\n",
    "      temperature: 0.7,      // 创造性: 0-1\n",
    "      topK: 40,             // 候选 token 数量\n",
    "      topP: 0.95,           // 概率质量阈值\n",
    "      maxOutputTokens: 1024 // 最大输出长度\n",
    "    },\n",
    "    safetySettings: [\n",
    "      {\n",
    "        category: 'HARM_CATEGORY_HARASSMENT',\n",
    "        threshold: 'BLOCK_MEDIUM_AND_ABOVE'\n",
    "      },\n",
    "      {\n",
    "        category: 'HARM_CATEGORY_HATE_SPEECH',\n",
    "        threshold: 'BLOCK_MEDIUM_AND_ABOVE'\n",
    "      }\n",
    "    ]\n",
    "  });\n",
    "\n",
    "  const result = await model.generateContent(\n",
    "    'Write a creative story about friendship'\n",
    "  );\n",
    "\n",
    "  return result.response.text();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ========== 6. 嵌入向量 ==========\n",
    "async function getEmbeddings() {\n",
    "  const model = genAI.getGenerativeModel({ model: 'embedding-001' });\n",
    "\n",
    "  const result = await model.embedContent('The quick brown fox jumps over the lazy dog.');\n",
    "  const embedding = result.embedding;\n",
    "\n",
    "  console.log('Embedding values:', embedding.values.length);\n",
    "  console.log('First 5 values:', embedding.values.slice(0, 5));\n",
    "\n",
    "  return embedding;\n",
    "}\n",
    "\n",
    "// 批量嵌入\n",
    "async function batchEmbeddings() {\n",
    "  const model = genAI.getGenerativeModel({ model: 'embedding-001' });\n",
    "\n",
    "  const texts = [\n",
    "    'How to make a sandwich',\n",
    "    'The history of bread',\n",
    "    'Healthy eating habits'\n",
    "  ];\n",
    "\n",
    "  const batchResult = await model.batchEmbedContents({\n",
    "    requests: texts.map(text => ({ content: { role: 'user', parts: [text] } }))\n",
    "  });\n",
    "\n",
    "  console.log('Number of embeddings:', batchResult.embeddings.length);\n",
    "  return batchResult.embeddings;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ========== 7. 函数调用 ==========\n",
    "async function functionCalling() {\n",
    "  const model = genAI.getGenerativeModel({\n",
    "    model: 'gemini-pro',\n",
    "    tools: [\n",
    "      {\n",
    "        functionDeclarations: [\n",
    "          {\n",
    "            name: 'getWeather',\n",
    "            description: 'Get the current weather in a given location',\n",
    "            parameters: {\n",
    "              type: 'object',\n",
    "              properties: {\n",
    "                location: {\n",
    "                  type: 'string',\n",
    "                  description: 'The city name, e.g. San Francisco'\n",
    "                },\n",
    "                unit: {\n",
    "                  type: 'string',\n",
    "                  enum: ['celsius', 'fahrenheit'],\n",
    "                  description: 'Temperature unit'\n",
    "                }\n",
    "              },\n",
    "              required: ['location']\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "            name: 'getExchangeRate',\n",
    "            description: 'Get the exchange rate between currencies',\n",
    "            parameters: {\n",
    "              type: 'object',\n",
    "              properties: {\n",
    "                from: {\n",
    "                  type: 'string',\n",
    "                  description: 'Source currency code'\n",
    "                },\n",
    "                to: {\n",
    "                  type: 'string',\n",
    "                  description: 'Target currency code'\n",
    "                }\n",
    "              },\n",
    "              required: ['from', 'to']\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  });\n",
    "\n",
    "  const chat = model.startChat();\n",
    "\n",
    "  // 发送消息\n",
    "  const result = await chat.sendMessage(\n",
    "    'What is the weather in Tokyo and the exchange rate from USD to JPY?'\n",
    "  );\n",
    "\n",
    "  const response = result.response;\n",
    "\n",
    "  // 检查是否有函数调用\n",
    "  const functionCalls = response.functionCalls();\n",
    "\n",
    "  if (functionCalls && functionCalls.length > 0) {\n",
    "    for (const call of functionCalls) {\n",
    "      console.log('Function call:', call.name, call.args);\n",
    "\n",
    "      // 执行函数并返回结果\n",
    "      const functionResult = await executeFunction(call.name, call.args);\n",
    "\n",
    "      // 发送函数结果回模型\n",
    "      const followUp = await chat.sendMessage([\n",
    "        {\n",
    "          functionResponse: {\n",
    "            name: call.name,\n",
    "            response: functionResult\n",
    "          }\n",
    "        }\n",
    "      ]);\n",
    "\n",
    "      console.log('Final response:', followUp.response.text());\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "async function executeFunction(name: string, args: any): Promise<any> {\n",
    "  if (name === 'getWeather') {\n",
    "    return { temperature: 25, condition: 'sunny', location: args.location };\n",
    "  }\n",
    "  if (name === 'getExchangeRate') {\n",
    "    return { rate: 150.5, from: args.from, to: args.to };\n",
    "  }\n",
    "  return {};\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "name": "typescript"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}