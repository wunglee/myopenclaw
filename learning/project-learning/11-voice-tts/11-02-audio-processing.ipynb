{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11-02: 音频处理与格式转换",
    "",
    "音频流处理、格式转换和 Web Audio API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ========== 1. 使用 FFmpeg 进行音频转换 ==========\n",
    "// 安装: npm install fluent-ffmpeg\n",
    "// 需要系统安装 FFmpeg\n",
    "import ffmpeg from 'fluent-ffmpeg';\n",
    "import { createReadStream, createWriteStream } from 'fs';\n",
    "import { Readable } from 'stream';\n",
    "",
    "// MP3 转 WAV\n",
    "function convertMp3ToWav(inputPath: string, outputPath: string): Promise<void> {\n",
    "  return new Promise((resolve, reject) => {\n",
    "    ffmpeg(inputPath)\n",
    "      .toFormat('wav')\n",
    "      .audioCodec('pcm_s16le')\n",
    "      .audioChannels(2)\n",
    "      .audioFrequency(44100)\n",
    "      .on('end', () => {\n",
    "        console.log('Conversion finished');\n",
    "        resolve();\n",
    "      })\n",
    "      .on('error', (err) => {\n",
    "        reject(err);\n",
    "      })\n",
    "      .save(outputPath);\n",
    "  });\n",
    "}\n",
    "",
    "// 流式转换\n",
    "function convertStream(inputStream: Readable, format: string): Readable {\n",
    "  return ffmpeg(inputStream)\n",
    "    .toFormat(format)\n",
    "    .pipe() as Readable;\n",
    "}\n",
    "",
    "// 压缩音频\n",
    "function compressAudio(\n",
    "  inputPath: string,\n",
    "  outputPath: string,\n",
    "  bitrate: string = '128k'\n",
    "): Promise<void> {\n",
    "  return new Promise((resolve, reject) => {\n",
    "    ffmpeg(inputPath)\n",
    "      .audioBitrate(bitrate)\n",
    "      .audioCodec('libmp3lame')\n",
    "      .on('end', resolve)\n",
    "      .on('error', reject)\n",
    "      .save(outputPath);\n",
    "  });\n",
    "}\n",
    "",
    "// 提取音频信息\n",
    "function getAudioInfo(inputPath: string): Promise<any> {\n",
    "  return new Promise((resolve, reject) => {\n",
    "    ffmpeg.ffprobe(inputPath, (err, metadata) => {\n",
    "      if (err) return reject(err);\n",
    "\n",
    "      const audioStream = metadata.streams.find((s: any) => s.codec_type === 'audio');\n",
    "      resolve({\n",
    "        duration: metadata.format.duration,\n",
    "        bitrate: metadata.format.bit_rate,\n",
    "        format: metadata.format.format_name,\n",
    "        codec: audioStream?.codec_name,\n",
    "        sampleRate: audioStream?.sample_rate,\n",
    "        channels: audioStream?.channels\n",
    "      });\n",
    "    });\n",
    "  });\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ========== 2. Web Audio API (Node.js 使用 web-audio-engine) ==========\n",
    "// 安装: npm install web-audio-engine\n",
    "import { AudioContext } from 'web-audio-engine';\n",
    "",
    "// 创建音频上下文\n",
    "const audioContext = new AudioContext();\n",
    "",
    "// 加载音频文件\n",
    "async function loadAudioFile(filePath: string): Promise<AudioBuffer> {\n",
    "  const fs = await import('fs/promises');\n",
    "  const data = await fs.readFile(filePath);\n",
    "\n",
    "  // 解码音频\n",
    "  const arrayBuffer = data.buffer.slice(\n",
    "    data.byteOffset,\n",
    "    data.byteOffset + data.byteLength\n",
    "  );\n",
    "\n",
    "  return audioContext.decodeAudioData(arrayBuffer);\n",
    "}\n",
    "",
    "// 音频处理：改变播放速度（不改变音调）\n",
    "function changePlaybackRate(audioBuffer: AudioBuffer, rate: number): AudioBuffer {\n",
    "  const source = audioContext.createBufferSource();\n",
    "  source.buffer = audioBuffer;\n",
    "  source.playbackRate.value = rate;\n",
    "\n",
    "  const destination = audioContext.createMediaStreamDestination();\n",
    "  source.connect(destination);\n",
    "\n",
    "  // 创建新的缓冲区\n",
    "  const newLength = Math.floor(audioBuffer.length / rate);\n",
    "  const newBuffer = audioContext.createBuffer(\n",
    "    audioBuffer.numberOfChannels,\n",
    "    newLength,\n",
    "    audioBuffer.sampleRate\n",
    "  );\n",
    "\n",
    "  for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {\n",
    "    const inputData = audioBuffer.getChannelData(channel);\n",
    "    const outputData = newBuffer.getChannelData(channel);\n",
    "\n",
    "    for (let i = 0; i < newLength; i++) {\n",
    "      const inputIndex = Math.floor(i * rate);\n",
    "      outputData[i] = inputData[inputIndex] || 0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return newBuffer;\n",
    "}\n",
    "",
    "// 调整音量\n",
    "function adjustVolume(audioBuffer: AudioBuffer, volume: number): AudioBuffer {\n",
    "  const newBuffer = audioContext.createBuffer(\n",
    "    audioBuffer.numberOfChannels,\n",
    "    audioBuffer.length,\n",
    "    audioBuffer.sampleRate\n",
    "  );\n",
    "\n",
    "  for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {\n",
    "    const inputData = audioBuffer.getChannelData(channel);\n",
    "    const outputData = newBuffer.getChannelData(channel);\n",
    "\n",
    "    for (let i = 0; i < audioBuffer.length; i++) {\n",
    "      outputData[i] = inputData[i] * volume;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return newBuffer;\n",
    "}\n",
    "",
    "// 淡入淡出\n",
    "function applyFade(audioBuffer: AudioBuffer, fadeInDuration: number, fadeOutDuration: number): AudioBuffer {\n",
    "  const newBuffer = audioContext.createBuffer(\n",
    "    audioBuffer.numberOfChannels,\n",
    "    audioBuffer.length,\n",
    "    audioBuffer.sampleRate\n",
    "  );\n",
    "\n",
    "  const sampleRate = audioBuffer.sampleRate;\n",
    "  const fadeInSamples = Math.floor(fadeInDuration * sampleRate);\n",
    "  const fadeOutSamples = Math.floor(fadeOutDuration * sampleRate);\n",
    "\n",
    "  for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {\n",
    "    const inputData = audioBuffer.getChannelData(channel);\n",
    "    const outputData = newBuffer.getChannelData(channel);\n",
    "\n",
    "    for (let i = 0; i < audioBuffer.length; i++) {\n",
    "      let gain = 1.0;\n",
    "\n",
    "      // 淡入\n",
    "      if (i < fadeInSamples) {\n",
    "        gain = i / fadeInSamples;\n",
    "      }\n",
    "      // 淡出\n",
    "      else if (i > audioBuffer.length - fadeOutSamples) {\n",
    "        gain = (audioBuffer.length - i) / fadeOutSamples;\n",
    "      }\n",
    "\n",
    "      outputData[i] = inputData[i] * gain;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return newBuffer;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ========== 3. 音频流处理 ==========\n",
    "import { Transform } from 'stream';\n",
    "",
    "// 音频流转换器\n",
    "class AudioTransform extends Transform {\n",
    "  private buffer: Buffer = Buffer.alloc(0);\n",
    "  private readonly sampleSize: number = 2; // 16-bit\n",
    "\n",
    "  constructor(private options: {\n",
    "    volume?: number;\n",
    "    sampleRate?: number;\n",
    "  }) {\n",
    "    super();\n",
    "  }\n",
    "\n",
    "  _transform(chunk: Buffer, encoding: string, callback: Function): void {\n",
    "    this.buffer = Buffer.concat([this.buffer, chunk]);\n",
    "\n",
    "    // 处理完整的样本\n",
    "    const samplesToProcess = Math.floor(this.buffer.length / this.sampleSize);\n",
    "    const processedLength = samplesToProcess * this.sampleSize;\n",
    "\n",
    "    if (samplesToProcess > 0) {\n",
    "      const output = this.processSamples(\n",
    "        this.buffer.slice(0, processedLength),\n",
    "        samplesToProcess\n",
    "      );\n",
    "\n",
    "      this.push(output);\n",
    "      this.buffer = this.buffer.slice(processedLength);\n",
    "    }\n",
    "\n",
    "    callback();\n",
    "  }\n",
    "\n",
    "  private processSamples(data: Buffer, sampleCount: number): Buffer {\n",
    "    const output = Buffer.alloc(data.length);\n",
    "    const volume = this.options.volume ?? 1.0;\n",
    "\n",
    "    for (let i = 0; i < sampleCount; i++) {\n",
    "      const offset = i * this.sampleSize;\n",
    "      let sample = data.readInt16LE(offset);\n",
    "\n",
    "      // 应用音量\n",
    "      sample = Math.max(-32768, Math.min(32767, Math.floor(sample * volume)));\n",
    "\n",
    "      output.writeInt16LE(sample, offset);\n",
    "    }\n",
    "\n",
    "    return output;\n",
    "  }\n",
    "}\n",
    "",
    "// 使用流处理\n",
    "function processAudioStream(\n",
    "  inputPath: string,\n",
    "  outputPath: string,\n",
    "  options: { volume?: number }\n",
    "): void {\n",
    "  const input = createReadStream(inputPath);\n",
    "  const transform = new AudioTransform(options);\n",
    "  const output = createWriteStream(outputPath);\n",
    "\n",
    "  input.pipe(transform).pipe(output);\n",
    "}\n",
    "",
    "// 流式音频播放器\n",
    "class AudioPlayer {\n",
    "  private currentStream?: Readable;\n",
    "\n",
    "  play(stream: Readable): void {\n",
    "    this.stop();\n",
    "    this.currentStream = stream;\n",
    "\n",
    "    // 实际播放需要音频输出设备\n",
    "    // 这里只是示例\n",
    "    stream.on('data', (chunk) => {\n",
    "      // 将数据发送到音频输出\n",
    "    });\n",
    "\n",
    "    stream.on('end', () => {\n",
    "      console.log('Playback finished');\n",
    "    });\n",
    "  }\n",
    "\n",
    "  stop(): void {\n",
    "    if (this.currentStream) {\n",
    "      this.currentStream.destroy();\n",
    "      this.currentStream = undefined;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  pause(): void {\n",
    "    this.currentStream?.pause();\n",
    "  }\n",
    "\n",
    "  resume(): void {\n",
    "    this.currentStream?.resume();\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ========== 4. 音频分割与合并 ==========\n",
    "// 分割音频\n",
    "function splitAudio(\n",
    "  inputPath: string,\n",
    "  segmentDuration: number,\n",
    "  outputPattern: string\n",
    "): Promise<string[]> {\n",
    "  return new Promise((resolve, reject) => {\n",
    "    const outputFiles: string[] = [];\n",
    "\n",
    "    ffmpeg(inputPath)\n",
    "      .outputOptions([\n",
    "        `-f segment`,\n",
    "        `-segment_time ${segmentDuration}`,\n",
    "        `-c copy`\n",
    "      ])\n",
    "      .output(outputPattern)\n",
    "      .on('end', () => resolve(outputFiles))\n",
    "      .on('error', reject)\n",
    "      .run();\n",
    "  });\n",
    "}\n",
    "",
    "// 合并音频文件\n",
    "function mergeAudioFiles(\n",
    "  inputFiles: string[],\n",
    "  outputPath: string\n",
    "): Promise<void> {\n",
    "  return new Promise((resolve, reject) => {\n",
    "    const command = ffmpeg();\n",
    "\n",
    "    inputFiles.forEach((file) => {\n",
    "      command.input(file);\n",
    "    });\n",
    "\n",
    "    command\n",
    "      .on('end', resolve)\n",
    "      .on('error', reject)\n",
    "      .mergeToFile(outputPath, '/tmp');\n",
    "  });\n",
    "}\n",
    "",
    "// 提取音频片段\n",
    "function extractSegment(\n",
    "  inputPath: string,\n",
    "  startTime: number,\n",
    "  duration: number,\n",
    "  outputPath: string\n",
    "): Promise<void> {\n",
    "  return new Promise((resolve, reject) => {\n",
    "    ffmpeg(inputPath)\n",
    "      .setStartTime(startTime)\n",
    "      .setDuration(duration)\n",
    "      .output(outputPath)\n",
    "      .on('end', resolve)\n",
    "      .on('error', reject)\n",
    "      .run();\n",
    "  });\n",
    "}\n",
    "",
    "// 拼接音频（带淡入淡出）\n",
    "function concatenateWithTransitions(\n",
    "  inputFiles: string[],\n",
    "  outputPath: string,\n",
    "  transitionDuration: number = 2\n",
    "): Promise<void> {\n",
    "  return new Promise((resolve, reject) => {\n",
    "    const filterComplex = inputFiles\n",
    "      .map((_, i) => `[${i}:a]`)\n",
    "      .join('') +\n",
    "      `concat=n=${inputFiles.length}:v=0:a=1[outa]`;\n",
    "\n",
    "    const command = ffmpeg();\n",
    "\n",
    "    inputFiles.forEach((file) => {\n",
    "      command.input(file);\n",
    "    });\n",
    "\n",
    "    command\n",
    "      .complexFilter(filterComplex, ['outa'])\n",
    "      .audioCodec('libmp3lame')\n",
    "      .audioBitrate('128k')\n",
    "      .output(outputPath)\n",
    "      .on('end', resolve)\n",
    "      .on('error', reject)\n",
    "      .run();\n",
    "  });\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ========== 5. 实时音频流 (WebSocket) ==========\n",
    "import { WebSocket } from 'ws';\n",
    "",
    "interface AudioStreamConfig {\n",
    "  sampleRate: number;\n",
    "  channels: number;\n",
    "  bitDepth: number;\n",
    "  bufferSize: number;\n",
    "}\n",
    "",
    "class RealtimeAudioStreamer {\n",
    "  private ws?: WebSocket;\n",
    "  private config: AudioStreamConfig = {\n",
    "    sampleRate: 16000,\n",
    "    channels: 1,\n",
    "    bitDepth: 16,\n",
    "    bufferSize: 4096\n",
    "  };\n",
    "\n",
    "  connect(url: string): void {\n",
    "    this.ws = new WebSocket(url);\n",
    "\n",
    "    this.ws.on('open', () => {\n",
    "      console.log('Connected to audio server');\n",
    "      // 发送配置\n",
    "      this.ws?.send(JSON.stringify({ type: 'config', ...this.config }));\n",
    "    });\n",
    "\n",
    "    this.ws.on('message', (data) => {\n",
    "      // 接收音频数据\n",
    "      if (data instanceof Buffer) {\n",
    "        this.onAudioData?.(data);\n",
    "      } else {\n",
    "        // 处理控制消息\n",
    "        const message = JSON.parse(data.toString());\n",
    "        this.onControlMessage?.(message);\n",
    "      }\n",
    "    });\n",
    "  }\n",
    "\n",
    "  sendAudioData(data: Buffer): void {\n",
    "    if (this.ws?.readyState === WebSocket.OPEN) {\n",
    "      this.ws.send(data);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  onAudioData?: (data: Buffer) => void;\n",
    "  onControlMessage?: (message: any) => void;\n",
    "\n",
    "  disconnect(): void {\n",
    "    this.ws?.close();\n",
    "  }\n",
    "}\n",
    "",
    "// PCM 格式音频编码器\n",
    "class PCMEncoder {\n",
    "  constructor(\n",
    "    private sampleRate: number,\n",
    "    private channels: number,\n",
    "    private bitDepth: number\n",
    "  ) {}\n",
    "\n",
    "  encode(samples: Float32Array): Buffer {\n",
    "    const bytesPerSample = this.bitDepth / 8;\n",
    "    const buffer = Buffer.alloc(samples.length * bytesPerSample);\n",
    "\n",
    "    for (let i = 0; i < samples.length; i++) {\n",
    "      const sample = Math.max(-1, Math.min(1, samples[i]));\n",
    "\n",
    "      if (this.bitDepth === 16) {\n",
    "        buffer.writeInt16LE(Math.floor(sample * 32767), i * bytesPerSample);\n",
    "      } else if (this.bitDepth === 32) {\n",
    "        buffer.writeInt32LE(Math.floor(sample * 2147483647), i * bytesPerSample);\n",
    "      }\n",
    "    }\n",
    "\n",
    "    return buffer;\n",
    "  }\n",
    "\n",
    "  decode(buffer: Buffer): Float32Array {\n",
    "    const bytesPerSample = this.bitDepth / 8;\n",
    "    const samples = new Float32Array(buffer.length / bytesPerSample);\n",
    "\n",
    "    for (let i = 0; i < samples.length; i++) {\n",
    "      if (this.bitDepth === 16) {\n",
    "        samples[i] = buffer.readInt16LE(i * bytesPerSample) / 32767;\n",
    "      } else if (this.bitDepth === 32) {\n",
    "        samples[i] = buffer.readInt32LE(i * bytesPerSample) / 2147483647;\n",
    "      }\n",
    "    }\n",
    "\n",
    "    return samples;\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "name": "typescript"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}