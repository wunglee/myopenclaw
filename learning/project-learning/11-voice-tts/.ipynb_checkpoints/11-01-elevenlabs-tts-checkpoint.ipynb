{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11-01 语音合成（TTS）\n",
    "\n",
    "使用 ElevenLabs 等 API 实现文本转语音。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ElevenLabs API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 使用 ElevenLabs API 生成语音\n",
    "async function textToSpeech(text, voiceId = '21m00Tcm4TlvDq8ikWAM') {\n",
    "  const response = await fetch(\n",
    "    `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`,\n",
    "    {\n",
    "      method: 'POST',\n",
    "      headers: {\n",
    "        'Accept': 'audio/mpeg',\n",
    "        'Content-Type': 'application/json',\n",
    "        'xi-api-key': process.env.ELEVENLABS_API_KEY\n",
    "      },\n",
    "      body: JSON.stringify({\n",
    "        text,\n",
    "        model_id: 'eleven_monolingual_v1',\n",
    "        voice_settings: {\n",
    "          stability: 0.5,\n",
    "          similarity_boost: 0.5\n",
    "        }\n",
    "      })\n",
    "    }\n",
    "  );\n",
    "  \n",
    "  if (!response.ok) {\n",
    "    throw new Error(`TTS failed: ${response.statusText}`);\n",
    "  }\n",
    "  \n",
    "  const audioBuffer = await response.arrayBuffer();\n",
    "  return Buffer.from(audioBuffer);\n",
    "}\n",
    "\n",
    "// 使用\n",
    "const fs = require('fs');\n",
    "const audio = await textToSpeech('你好，这是语音合成的测试。');\n",
    "fs.writeFileSync('output.mp3', audio);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 流式语音生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 流式获取音频\n",
    "async function streamTTS(text, voiceId) {\n",
    "  const response = await fetch(\n",
    "    `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}/stream`,\n",
    "    {\n",
    "      method: 'POST',\n",
    "      headers: {\n",
    "        'Accept': 'audio/mpeg',\n",
    "        'Content-Type': 'application/json',\n",
    "        'xi-api-key': process.env.ELEVENLABS_API_KEY\n",
    "      },\n",
    "      body: JSON.stringify({ text, model_id: 'eleven_monolingual_v1' })\n",
    "    }\n",
    "  );\n",
    "  \n",
    "  const reader = response.body.getReader();\n",
    "  const chunks = [];\n",
    "  \n",
    "  while (true) {\n",
    "    const { done, value } = await reader.read();\n",
    "    if (done) break;\n",
    "    chunks.push(value);\n",
    "  }\n",
    "  \n",
    "  return Buffer.concat(chunks);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 多语音对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 对话配置\n",
    "const voices = {\n",
    "  alice: '21m00Tcm4TlvDq8ikWAM',  // Rachel\n",
    "  bob: 'AZnzlk1XvdvUeBnXmlld'      // Adam\n",
    "};\n",
    "\n",
    "const conversation = [\n",
    "  { speaker: 'alice', text: '你好 Bob，今天过得怎么样？' },\n",
    "  { speaker: 'bob', text: '还不错 Alice，我刚完成了一个新项目。' },\n",
    "  { speaker: 'alice', text: '太棒了！能给我讲讲吗？' }\n",
    "];\n",
    "\n",
    "// 生成对话音频\n",
    "async function generateConversation(conversation) {\n",
    "  for (let i = 0; i < conversation.length; i++) {\n",
    "    const { speaker, text } = conversation[i];\n",
    "    const voiceId = voices[speaker];\n",
    "    \n",
    "    const audio = await textToSpeech(text, voiceId);\n",
    "    fs.writeFileSync(`dialogue_${i}_${speaker}.mp3`, audio);\n",
    "    console.log(`Generated: ${speaker} - ${text.substring(0, 30)}...`);\n",
    "  }\n",
    "}\n",
    "\n",
    "await generateConversation(conversation);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. WebSocket 实时语音（OpenClaw 风格）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// WebSocket 实时语音服务\n",
    "import { WebSocketServer } from 'ws';\n",
    "\n",
    "const wss = new WebSocketServer({ port: 8080 });\n",
    "\n",
    "wss.on('connection', (ws) => {\n",
    "  console.log('Client connected');\n",
    "  \n",
    "  ws.on('message', async (data) => {\n",
    "    const { text, voiceId } = JSON.parse(data);\n",
    "    \n",
    "    try {\n",
    "      // 生成语音\n",
    "      const audio = await textToSpeech(text, voiceId);\n",
    "      \n",
    "      // 发送音频数据\n",
    "      ws.send(audio);\n",
    "    } catch (error) {\n",
    "      ws.send(JSON.stringify({ error: error.message }));\n",
    "    }\n",
    "  });\n",
    "  \n",
    "  ws.on('close', () => {\n",
    "    console.log('Client disconnected');\n",
    "  });\n",
    "});\n",
    "\n",
    "console.log('TTS WebSocket server running on ws://localhost:8080');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习\n",
    "\n",
    "1. 实现一个带语音的聊天机器人\n",
    "2. 生成一篇博客文章的语音版\n",
    "3. 查看 OpenClaw 的语音处理实现"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "name": "typescript"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}